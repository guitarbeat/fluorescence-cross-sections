"""
    --- AUTO-GENERATED DOCSTRING ---
    Table of content is automatically generated by Agent Docstrings v1.3.5

    Classes/Functions:
        - load_water_absorption_data() -> pd.DataFrame (line 40)
        - load_fluorophore_data() -> pd.DataFrame (line 69)
        - load_cross_section_data() -> Dict[str, pd.DataFrame] (line 85)
        
    --- END AUTO-GENERATED DOCSTRING ---

Data loading utilities for handling various data sources including:
- Water absorption data
- Fluorophore data
- Two-photon cross-section data
"""
import logging
from typing import Dict

import numpy as np
import pandas as pd
import streamlit as st

from fluorescence.config import DATA_DIR, FLUOROPHORE_COLUMNS, FLUOROPHORE_CSV

logger = logging.getLogger(__name__)

# Constants
XSECTION_DIR = DATA_DIR / "2p-xsections"
DEFAULT_COLUMNS = FLUOROPHORE_COLUMNS


def load_water_absorption_data() -> pd.DataFrame:
    """
    Load water absorption data from kou93b.dat.

    Returns:
        pd.DataFrame: DataFrame containing wavelength and absorption data
    """
    data_path = DATA_DIR / "kou93b.dat"
    try:
        df = pd.read_csv(
            data_path,
            sep=r'\s+',
            skiprows=6,
            names=["wavelength", "absorption"],
            encoding="latin1",
            comment="#",
        )
        # Flip the data as in the MATLAB code
        df = df.iloc[::-1].reset_index(drop=True)
        return df
    except (FileNotFoundError, pd.errors.EmptyDataError) as e:
        st.error(f"Error loading water absorption data: {e}")
        return pd.DataFrame({
            "wavelength": np.linspace(800, 2400, 1000),
            "absorption": np.zeros(1000),
        })


def load_fluorophore_data() -> pd.DataFrame:
    """
    Load existing fluorophores from CSV or create empty DataFrame.

    Returns:
        pd.DataFrame: DataFrame containing fluorophore data
    """
    try:
        return pd.read_csv(FLUOROPHORE_CSV)
    except (FileNotFoundError, pd.errors.EmptyDataError) as e:
        st.warning(f"No existing fluorophore data found: {e}")
        return pd.DataFrame(columns=DEFAULT_COLUMNS)


def _clean_and_validate_cross_section_df(df: pd.DataFrame, file_path, logger) -> pd.DataFrame:
    """Assigns column names, cleans, converts, validates, and sorts the DataFrame for cross-section data."""
    # Assign column names based on number of columns
    if len(df.columns) >= 2:
        if len(df.columns) == 3:
            df.columns = ["wavelength", "cross_section", "std_dev"]
        else:
            df.columns = ["wavelength", "cross_section"]
    else:
        logger.error(
            f"Could not parse {file_path.name} - insufficient columns after header detection")
        return None

    # Clean and validate data
    df = df.drop_duplicates()
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.dropna(how='all', subset=df.columns[1:])
    df = df.sort_values('wavelength')
    if df.empty or df['wavelength'].isna().all():
        logger.warning(f"No valid data found in {file_path}")
        return None
    logger.debug(f"First few rows of {file_path.name}:\n{df.head()}")
    return df


@st.cache_data
def load_cross_section_data() -> Dict[str, pd.DataFrame]:
    """Load all two-photon cross-section data files."""
    cross_sections: Dict[str, pd.DataFrame] = {}

    if not XSECTION_DIR.exists():
        st.error(f"Cross-section directory not found: {XSECTION_DIR}")
        return cross_sections

    # Define special case configurations with exact header handling
    SPECIAL_CASES = {
        "IntrinsicFluorophores": {
            "skiprows": [0, 1],  # Skip title and separator lines
            "names": ["wavelength", "riboflavin", "folic_acid", "cholecalciferol", "retinol"],
            "description": "Intrinsic fluorophores including riboflavin, folic acid, etc.",
            "delimiter": r"\s+",
            "encoding": "utf-8",
            "decimal": ".",  # Handle scientific notation
            "thousands": None  # No thousands separator
        },
        "NADH-ProteinBound": {
            "skiprows": [0, 1, 2],  # Skip all header lines
            "names": ["wavelength", "gm_mean", "sd", "gm_mdh", "gm_ad"],
            "description": "NADH in different binding states",
            "delimiter": r"\s+",
            "encoding": "utf-8",
            "decimal": ".",
            "thousands": None
        },
        "Fura2": {
            "skiprows": [0, 1, 2],  # Skip header lines
            "names": ["wavelength", "gm_mean_ca", "sd_ca", "gm_mean_free", "sd_free"],
            "description": "Fura-2 with and without calcium",
            "delimiter": r"\s+",
            "encoding": "utf-8",
            "decimal": ".",
            "thousands": None
        }
    }

    for file_path in XSECTION_DIR.glob("*.txt"):
        try:
            fluorophore_name = file_path.stem

            if fluorophore_name in SPECIAL_CASES:
                config = SPECIAL_CASES[fluorophore_name]
                # Read the file with exact configuration
                df = pd.read_csv(
                    file_path,
                    sep=config["delimiter"],
                    skiprows=config["skiprows"],
                    names=config["names"],
                    encoding=config["encoding"],
                    engine='python',
                    decimal=config["decimal"],
                    thousands=config["thousands"]
                )
                # Add metadata
                df.attrs['description'] = config.get('description', '')
            else:
                # Read the file to determine header structure
                with open(file_path, 'r') as f:
                    lines = f.readlines()

                # Find where the data starts (after header lines)
                data_start = 0
                for i, line in enumerate(lines):
                    line = line.strip()
                    # Skip empty lines, comment lines, and header lines
                    if (line and
                        not line.startswith('#') and
                        not line.startswith('--') and
                        not line.startswith('nm') and
                        not 'GM' in line and
                        not 'mean' in line and
                        not 'sd' in line and
                        not '@' in line and
                            not 'n=' in line):
                        # Check if this line looks like data (starts with a number)
                        parts = line.split()
                        if parts and parts[0].replace('.', '').replace('-', '').replace('e', '').replace('E', '').isdigit():
                            data_start = i
                            break

                # Read data with tab separator, skipping header lines
                logger.debug(
                    f"Reading {file_path.name} with skiprows={data_start}")
                df = pd.read_csv(
                    file_path,
                    sep='\t',
                    engine='python',
                    comment='#',
                    skiprows=data_start
                )

                # Check if we got the expected columns
                cleaned_df = _clean_and_validate_cross_section_df(
                    df, file_path, logger)
                if cleaned_df is None:
                    # Try with whitespace separator
                    df = pd.read_csv(
                        file_path,
                        sep=r'\s+',
                        engine='python',
                        comment='#',
                        skiprows=data_start
                    )
                    cleaned_df = _clean_and_validate_cross_section_df(
                        df, file_path, logger)
                    if cleaned_df is None:
                        continue
                df = cleaned_df

            # Log the first few rows for debugging
            # logger.debug(f"First few rows of {fluorophore_name}:\n{df.head()}") # This line is now handled by _clean_and_validate_cross_section_df

            cross_sections[fluorophore_name] = df

        except Exception as e:
            st.error(
                f"Error loading cross-section data for {file_path.name}: {e}")
            logger.error(
                f"Failed to load {file_path}: {str(e)}", exc_info=True)
            # Add more detailed error information
            try:
                with open(file_path, 'r') as f:
                    first_lines = [f.readline().strip() for _ in range(10)]
                logger.error(
                    f"First 10 lines of {file_path.name}: {first_lines}")
            except Exception as read_error:
                logger.error(
                    f"Could not read file contents for debugging: {read_error}")

    if not cross_sections:
        st.warning("No cross-section data files were loaded successfully")

    return cross_sections


def compile_fluorophore_data(cross_sections: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Compile peak wavelengths and statistics into a single DataFrame.
    Args:
        cross_sections: Dict mapping fluorophore names to their cross-section DataFrames.
    Returns:
        pd.DataFrame: DataFrame with peak wavelength and cross-section statistics for each fluorophore.
    """
    data = []
    for name, df in cross_sections.items():
        stats = {'Name': name}
        if name == "IntrinsicFluorophores":
            for col in ["riboflavin", "folic_acid", "cholecalciferol", "retinol"]:
                peak_idx = df[col].idxmax()
                stats[f"{col}_peak_wavelength"] = df.loc[peak_idx, "wavelength"]
                stats[f"{col}_peak_cross_section"] = df.loc[peak_idx, col]
        elif name == "NADH-ProteinBound":
            for col in ["gm_mean", "gm_mdh", "gm_ad"]:
                peak_idx = df[col].idxmax()
                stats[f"{col}_peak_wavelength"] = df.loc[peak_idx, "wavelength"]
                stats[f"{col}_peak_cross_section"] = df.loc[peak_idx, col]
        else:
            cross_section_col = "cross_section" if "cross_section" in df.columns else df.columns[
                1]
            peak_idx = df[cross_section_col].idxmax()
            stats["peak_wavelength"] = df.loc[peak_idx, "wavelength"]
            stats["peak_cross_section"] = df.loc[peak_idx, cross_section_col]
        data.append(stats)
    return pd.DataFrame(data)
